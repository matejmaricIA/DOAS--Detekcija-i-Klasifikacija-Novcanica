{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### **1. Install the required dependencies**","metadata":{}},{"cell_type":"code","source":"!pip install ultralytics\n!git clone https://github.com/ultralytics/yolov5  # clone\n!cd yolov5\n!pip install -r requirements.txt  # install\n!pip install clearml\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-05-21T22:57:20.616927Z","iopub.execute_input":"2023-05-21T22:57:20.617370Z","iopub.status.idle":"2023-05-21T22:57:56.645618Z","shell.execute_reply.started":"2023-05-21T22:57:20.617323Z","shell.execute_reply":"2023-05-21T22:57:56.644454Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import DataLoader\nfrom torch.utils.data import Dataset\nimport torchvision.transforms as transforms\nfrom PIL import Image\nimport yaml\nimport os\nimport shutil\nimport random","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nAPI_ACCESS_KEY = user_secrets.get_secret(\"CLEARML_API_ACCESS_KEY\")\nAPI_SECRET_KEY = user_secrets.get_secret(\"CLEARML_API_SECRET_KEY\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%env CLEARML_WEB_HOST=https://app.clear.ml\n%env CLEARML_API_HOST=https://api.clear.ml\n%env CLEARML_FILES_HOST=https://files.clear.ml\n%env CLEARML_API_ACCESS_KEY=API_ACCESS_KEY\n%env CLEARML_API_SECRET_KEY=API_SECRET_KEY","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from clearml import Task\ntask = Task.init(project_name=\"Bank Note Detection and Classification\", task_name=\"Detection 250 epochs\")\n  \n\n","metadata":{"execution":{"iopub.status.busy":"2023-05-21T22:57:56.661991Z","iopub.execute_input":"2023-05-21T22:57:56.662327Z","iopub.status.idle":"2023-05-21T22:58:13.537754Z","shell.execute_reply.started":"2023-05-21T22:57:56.662295Z","shell.execute_reply":"2023-05-21T22:58:13.536055Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"},{"name":"stdout","text":"ClearML Task: created new task id=0db7f991719e44b586f76e259125a008\n2023-05-21 22:58:03,350 - clearml.Task - INFO - Storing jupyter notebook directly as code\nClearML results page: https://app.clear.ml/projects/ad200e2164044bcfb399eb7335e7081b/experiments/0db7f991719e44b586f76e259125a008/output/log\n","output_type":"stream"}]},{"cell_type":"code","source":"dataset_path = \"/kaggle/input/euro-banknotes/dataset\"\nimages_path = os.path.join(dataset_path, \"data/images\")\nlabels_path = os.path.join(dataset_path, \"data/labels\")\ndata_yaml_path = os.path.join(dataset_path, \"data.yaml\")","metadata":{"execution":{"iopub.status.busy":"2023-05-21T22:58:13.880091Z","iopub.execute_input":"2023-05-21T22:58:13.882609Z","iopub.status.idle":"2023-05-21T22:58:13.888987Z","shell.execute_reply.started":"2023-05-21T22:58:13.882569Z","shell.execute_reply":"2023-05-21T22:58:13.888010Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"train_ratio = 0.7\nval_ratio = 0.15\ntest_ratio = 0.15","metadata":{"execution":{"iopub.status.busy":"2023-05-21T22:58:13.891608Z","iopub.execute_input":"2023-05-21T22:58:13.892481Z","iopub.status.idle":"2023-05-21T22:58:13.900140Z","shell.execute_reply.started":"2023-05-21T22:58:13.892456Z","shell.execute_reply":"2023-05-21T22:58:13.899010Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"output_path = \"/kaggle/working/dataset\"\ntrain_path = os.path.join(output_path, \"train\")\nval_path = os.path.join(output_path, \"val\")\ntest_path = os.path.join(output_path, \"test\")\n","metadata":{"execution":{"iopub.status.busy":"2023-05-21T22:58:13.901640Z","iopub.execute_input":"2023-05-21T22:58:13.902044Z","iopub.status.idle":"2023-05-21T22:58:13.912937Z","shell.execute_reply.started":"2023-05-21T22:58:13.902012Z","shell.execute_reply":"2023-05-21T22:58:13.910580Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"os.makedirs(train_path, exist_ok=True)\nos.makedirs(val_path, exist_ok=True)\nos.makedirs(test_path, exist_ok=True)\n\n# Load data.yaml\nwith open(data_yaml_path, 'r') as file:\n    data_yaml = yaml.load(file, Loader=yaml.FullLoader)\n\n# Get all image and label filenames\nimage_files = os.listdir(images_path)\nlabel_files = os.listdir(labels_path)\n\n# Shuffle the filenames\nrandom.shuffle(image_files)\n\n# Calculate split indices\ntrain_split = int(len(image_files) * train_ratio)\nval_split = int(len(image_files) * (train_ratio + val_ratio))\n\n# Split image and label filenames\ntrain_images = image_files[:train_split]\nval_images = image_files[train_split:val_split]\ntest_images = image_files[val_split:]\n\n# Move images to corresponding directories\nfor image in train_images:\n    shutil.copy(os.path.join(images_path, image), train_path)\nfor image in val_images:\n    shutil.copy(os.path.join(images_path, image), val_path)\nfor image in test_images:\n    shutil.copy(os.path.join(images_path, image), test_path)\n\n# Move labels to corresponding directories\nfor image in train_images:\n    shutil.copy(os.path.join(labels_path, image.replace(\".jpg\", \".txt\")), train_path)\nfor image in val_images:\n    shutil.copy(os.path.join(labels_path, image.replace(\".jpg\", \".txt\")), val_path)\nfor image in test_images:\n    shutil.copy(os.path.join(labels_path, image.replace(\".jpg\", \".txt\")), test_path)","metadata":{"execution":{"iopub.status.busy":"2023-05-21T22:58:13.914354Z","iopub.execute_input":"2023-05-21T22:58:13.914800Z","iopub.status.idle":"2023-05-21T22:58:16.402926Z","shell.execute_reply.started":"2023-05-21T22:58:13.914764Z","shell.execute_reply":"2023-05-21T22:58:16.401918Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"data_yaml = \"\"\"\ntrain: /kaggle/working/dataset/train\nval: /kaggle/working/dataset/val\ntest: /kaggle/working/dataset/test\n\nnc: 1  # Number of classes\nnames: ['0']\n\"\"\"\n\n# Set the file path to save the data.yaml\ndata_yaml_path = '/kaggle/working/dataset/data.yaml'\n\n# Save the data.yaml file\nwith open(data_yaml_path, 'w') as file:\n    file.write(data_yaml)","metadata":{"execution":{"iopub.status.busy":"2023-05-21T22:58:16.406393Z","iopub.execute_input":"2023-05-21T22:58:16.406692Z","iopub.status.idle":"2023-05-21T22:58:16.414792Z","shell.execute_reply.started":"2023-05-21T22:58:16.406641Z","shell.execute_reply":"2023-05-21T22:58:16.413601Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# Load data.yaml\nwith open(data_yaml_path, 'r') as file:\n    data_yaml = yaml.load(file, Loader=yaml.FullLoader)","metadata":{"execution":{"iopub.status.busy":"2023-05-21T22:58:16.419215Z","iopub.execute_input":"2023-05-21T22:58:16.419503Z","iopub.status.idle":"2023-05-21T22:58:16.428277Z","shell.execute_reply.started":"2023-05-21T22:58:16.419478Z","shell.execute_reply":"2023-05-21T22:58:16.427238Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"!python yolov5/train.py --img 640 --batch 32 --epochs 250 --data /kaggle/working/dataset/data.yaml --weights /kaggle/working/yolov5x.pt\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!python yolov5/val.py --img 640 --data /kaggle/working/dataset/data.yaml --weights yolov5/runs/train/exp/weights/best.pt --half","metadata":{"execution":{"iopub.status.busy":"2023-05-21T23:57:02.169261Z","iopub.execute_input":"2023-05-21T23:57:02.169696Z","iopub.status.idle":"2023-05-21T23:57:26.372118Z","shell.execute_reply.started":"2023-05-21T23:57:02.169623Z","shell.execute_reply":"2023-05-21T23:57:26.370930Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"\u001b[34m\u001b[1mval: \u001b[0mdata=/kaggle/working/dataset/data.yaml, weights=['yolov5/runs/train/exp/weights/best.pt'], batch_size=32, imgsz=640, conf_thres=0.001, iou_thres=0.6, max_det=300, task=val, device=, workers=8, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=yolov5/runs/val, name=exp, exist_ok=False, half=True, dnn=False\nYOLOv5 ğŸš€ v7.0-169-geef637c Python-3.10.10 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n\nFusing layers... \nModel summary: 322 layers, 86173414 parameters, 0 gradients, 203.8 GFLOPs\n\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/val.cache... 40 images, 3 backgrounds, 0 c\u001b[0m\n                 Class     Images  Instances          P          R      mAP50   \n                   all         40        185      0.961      0.962      0.966      0.938\nSpeed: 0.2ms pre-process, 31.5ms inference, 2.2ms NMS per image at shape (32, 3, 640, 640)\nResults saved to \u001b[1myolov5/runs/val/exp\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"!python yolov5/val.py --weights yolov5/runs/train/exp/weights/best.pt --data /kaggle/working/dataset/data.yaml --img 832 --augment --half","metadata":{"execution":{"iopub.status.busy":"2023-05-21T23:57:26.373885Z","iopub.execute_input":"2023-05-21T23:57:26.374305Z","iopub.status.idle":"2023-05-21T23:57:48.492873Z","shell.execute_reply.started":"2023-05-21T23:57:26.374268Z","shell.execute_reply":"2023-05-21T23:57:48.491727Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"\u001b[34m\u001b[1mval: \u001b[0mdata=/kaggle/working/dataset/data.yaml, weights=['yolov5/runs/train/exp/weights/best.pt'], batch_size=32, imgsz=832, conf_thres=0.001, iou_thres=0.6, max_det=300, task=val, device=, workers=8, single_cls=False, augment=True, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=yolov5/runs/val, name=exp, exist_ok=False, half=True, dnn=False\nYOLOv5 ğŸš€ v7.0-169-geef637c Python-3.10.10 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n\nFusing layers... \nModel summary: 322 layers, 86173414 parameters, 0 gradients, 203.8 GFLOPs\n\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/val.cache... 40 images, 3 backgrounds, 0 c\u001b[0m\n                 Class     Images  Instances          P          R      mAP50   \n                   all         40        185      0.955      0.957      0.953      0.916\nSpeed: 0.4ms pre-process, 94.6ms inference, 1.4ms NMS per image at shape (32, 3, 832, 832)\nResults saved to \u001b[1myolov5/runs/val/exp2\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"!python yolov5/detect.py --weights yolov5/runs/train/exp/weights/best.pt --source /kaggle/input/euro-banknotes/dataset/data/images --img 640 --half --save-txt --save-crop","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2023-05-21T23:57:49.528490Z","iopub.execute_input":"2023-05-21T23:57:49.529124Z","iopub.status.idle":"2023-05-21T23:57:58.272264Z","shell.execute_reply.started":"2023-05-21T23:57:49.529089Z","shell.execute_reply":"2023-05-21T23:57:58.271066Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"\u001b[34m\u001b[1msegment/predict: \u001b[0mweights=['yolov5/runs/train-seg/exp/weights/best.pt'], source=/kaggle/input/euro-banknotes/dataset/data/images, data=yolov5/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=True, save_conf=False, save_crop=True, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov5/runs/predict-seg, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=True, dnn=False, vid_stride=1, retina_masks=False\nYOLOv5 ğŸš€ v7.0-169-geef637c Python-3.10.10 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n\nTraceback (most recent call last):\n  File \"/kaggle/working/yolov5/segment/predict.py\", line 284, in <module>\n    main(opt)\n  File \"/kaggle/working/yolov5/segment/predict.py\", line 279, in main\n    run(**vars(opt))\n  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n    return func(*args, **kwargs)\n  File \"/kaggle/working/yolov5/segment/predict.py\", line 101, in run\n    model = DetectMultiBackend(weights, device=device, dnn=dnn, data=data, fp16=half)\n  File \"/kaggle/working/yolov5/models/common.py\", line 344, in __init__\n    model = attempt_load(weights if isinstance(weights, list) else w, device=device, inplace=True, fuse=fuse)\n  File \"/kaggle/working/yolov5/models/experimental.py\", line 79, in attempt_load\n    ckpt = torch.load(attempt_download(w), map_location='cpu')  # load\n  File \"/opt/conda/lib/python3.10/site-packages/torch/serialization.py\", line 791, in load\n    with _open_file_like(f, 'rb') as opened_file:\n  File \"/opt/conda/lib/python3.10/site-packages/torch/serialization.py\", line 271, in _open_file_like\n    return _open_file(name_or_buffer, mode)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/serialization.py\", line 252, in __init__\n    super().__init__(open(name, mode))\nFileNotFoundError: [Errno 2] No such file or directory: 'yolov5/runs/train-seg/exp/weights/best.pt'\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}